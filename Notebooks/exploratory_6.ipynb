{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_name  item_id  \\\n",
      "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
      "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
      "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
      "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
      "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
      "\n",
      "   item_category_id  \n",
      "0                40  \n",
      "1                76  \n",
      "2                40  \n",
      "3                40  \n",
      "4                40  \n",
      "(22170, 3)\n",
      "(22170, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "items = pd.read_csv(r\"..\\Data\\Raw\\items.csv\", delimiter=\",\")\n",
    "print(items.head())\n",
    "print(items.shape)\n",
    "items = items.drop_duplicates(subset=['item_name'], keep=False)\n",
    "print(items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  shop_id  item_id\n",
      "0   0        5     5037\n",
      "1   1        5     5320\n",
      "2   2        5     5233\n",
      "3   3        5     5232\n",
      "4   4        5     5268\n",
      "42\n",
      "214200\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(r\"..\\Data\\Raw\\test.csv\", delimiter=\",\")\n",
    "print(test.head())\n",
    "print(test['shop_id'].nunique())\n",
    "print(test['ID'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
      "0  02.01.2013               0       59    22154      999.00           1.0\n",
      "1  03.01.2013               0       25     2552      899.00           1.0\n",
      "2  05.01.2013               0       25     2552      899.00          -1.0\n",
      "3  06.01.2013               0       25     2554     1709.05           1.0\n",
      "4  15.01.2013               0       25     2555     1099.00           1.0\n",
      "(2935849, 6)\n",
      "(2935793, 6)\n",
      "(2935789, 6)\n",
      "                               item_cnt_day item_price revenue\n",
      "                                        sum     median     sum\n",
      "date_block_num shop_id item_id                                \n",
      "0              0       32               6.0      221.0  1326.0\n",
      "                       33               3.0      347.0  1041.0\n",
      "                       35               1.0      247.0   247.0\n",
      "                       43               1.0      221.0   221.0\n",
      "                       51               2.0      128.5   257.0\n",
      "                       61               1.0      195.0   195.0\n",
      "                       75               1.0       76.0    76.0\n",
      "                       88               1.0       76.0    76.0\n",
      "                       95               1.0      193.0   193.0\n",
      "                       96               1.0       70.0    70.0\n",
      "                       98              25.0      268.0  6700.0\n",
      "                       111              1.0       89.0    89.0\n",
      "                       149              3.0       99.0   297.0\n",
      "                       151              1.0       75.0    75.0\n",
      "                       153              1.0      258.0   258.0\n",
      "                       198              1.0      112.0   112.0\n",
      "                       210              2.0      118.0   236.0\n",
      "                       282              1.0      109.0   109.0\n",
      "                       306              1.0       59.0    59.0\n",
      "                       351              1.0       89.0    89.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               item_cnt_day item_price  revenue\n                                        sum     median      sum\ndate_block_num shop_id item_id                                 \n29             19      16138            1.0      679.0    679.0\n11             7       6501             9.0      349.5   3145.5\n4              52      177              1.0      250.0    250.0\n9              35      19461            1.0      249.0    249.0\n3              51      11711            5.0      207.0   1035.0\n1              0       13517            7.0     2300.0  17573.0\n11             25      9595             1.0      199.0    199.0\n2              57      3743             2.0      559.0   1118.0\n14             35      6692             1.0     4599.0   4599.0\n               54      22016            1.0      199.0    199.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>item_cnt_day</th>\n      <th>item_price</th>\n      <th>revenue</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>sum</th>\n      <th>median</th>\n      <th>sum</th>\n    </tr>\n    <tr>\n      <th>date_block_num</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <th>19</th>\n      <th>16138</th>\n      <td>1.0</td>\n      <td>679.0</td>\n      <td>679.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <th>7</th>\n      <th>6501</th>\n      <td>9.0</td>\n      <td>349.5</td>\n      <td>3145.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>52</th>\n      <th>177</th>\n      <td>1.0</td>\n      <td>250.0</td>\n      <td>250.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <th>35</th>\n      <th>19461</th>\n      <td>1.0</td>\n      <td>249.0</td>\n      <td>249.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>51</th>\n      <th>11711</th>\n      <td>5.0</td>\n      <td>207.0</td>\n      <td>1035.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <th>0</th>\n      <th>13517</th>\n      <td>7.0</td>\n      <td>2300.0</td>\n      <td>17573.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <th>25</th>\n      <th>9595</th>\n      <td>1.0</td>\n      <td>199.0</td>\n      <td>199.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>57</th>\n      <th>3743</th>\n      <td>2.0</td>\n      <td>559.0</td>\n      <td>1118.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">14</th>\n      <th>35</th>\n      <th>6692</th>\n      <td>1.0</td>\n      <td>4599.0</td>\n      <td>4599.0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <th>22016</th>\n      <td>1.0</td>\n      <td>199.0</td>\n      <td>199.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(r\"..\\Data\\Raw\\sales_train.csv\", delimiter=\",\")\n",
    "print(sales.head())\n",
    "print(sales.shape)\n",
    "sales = sales.drop_duplicates(subset=['date', 'shop_id', 'item_id'], keep=False)\n",
    "print(sales.shape)\n",
    "sales = sales[sales.item_cnt_day<1000]\n",
    "sales = sales[sales.item_price<60000]\n",
    "sales = sales[sales.item_price>0]\n",
    "print(sales.shape)\n",
    "sales['revenue'] = sales['item_cnt_day'] * sales['item_price']\n",
    "sales_monthly = sales.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg({'item_cnt_day': ['sum'], 'item_price':['median'], 'revenue':['sum']})\n",
    "print(sales_monthly.head(20))\n",
    "sales_monthly.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_block_num\n",
      "0               1\n",
      "1               2\n",
      "2               3\n",
      "3               4\n",
      "4               5\n",
      "(7068600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\latest pycharm\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#join to test set to get only necessary IDs\n",
    "month_range = range(1, 34)\n",
    "month_df = pd.DataFrame(month_range)\n",
    "\n",
    "month_df.rename(columns={0 :'date_block_num'}, inplace=True )\n",
    "print(month_df.head())\n",
    "month_df['temp'] = 1\n",
    "test['temp'] = 1\n",
    "test_monthly = test.merge(month_df, on=['temp'])\n",
    "test_monthly.drop(['temp'], axis=1, inplace=True)\n",
    "whole_df = test_monthly.merge(sales_monthly, how='left', on=['date_block_num', 'item_id', 'shop_id'])\n",
    "whole_df.sample(10)\n",
    "print(whole_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item_category_name  item_category_id\n",
      "0  PC - Гарнитуры/Наушники                 0\n",
      "1         Аксессуары - PS2                 1\n",
      "2         Аксессуары - PS3                 2\n",
      "3         Аксессуары - PS4                 3\n",
      "4         Аксессуары - PSP                 4\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_csv(r\"..\\Data\\Raw\\item_categories.csv\", delimiter=\",\")\n",
    "print(categories.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22170, 3)\n",
      "(84, 2)\n",
      "(22170, 4)\n",
      "                                           item_name  item_id  \\\n",
      "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
      "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
      "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
      "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
      "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
      "\n",
      "   item_category_id                    item_category_name  \n",
      "0                40                            Кино - DVD  \n",
      "1                76  Программы - Для дома и офиса (Цифра)  \n",
      "2                40                            Кино - DVD  \n",
      "3                40                            Кино - DVD  \n",
      "4                40                            Кино - DVD  \n",
      "   item_id  item_category_id\n",
      "0        0                40\n",
      "1        1                76\n",
      "2        2                40\n",
      "3        3                40\n",
      "4        4                40\n",
      "22170\n",
      "(22170, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "             ID  shop_id  item_id  date_block_num  (item_cnt_day, sum)  \\\n2895675   87747       18    13236              25                  NaN   \n4180000  126666       52     1809              23                  1.0   \n4195543  127137       52     1866              23                  NaN   \n31663       959        5    16988              17                  NaN   \n4302373  130374       47     7327              32                  NaN   \n1204528   36500       12    13226              29                  NaN   \n2156249   65340       22    22013              30                  NaN   \n1095009   33182       10      892               4                  NaN   \n510386    15466        3    10515               9                  NaN   \n4153187  125854       52    14969               6                  NaN   \n\n         (item_price, median)  (revenue, sum)  item_category_id  \n2895675                   NaN             NaN                47  \n4180000                 349.0           349.0                30  \n4195543                   NaN             NaN                24  \n31663                     NaN             NaN                40  \n4302373                   NaN             NaN                55  \n1204528                   NaN             NaN                47  \n2156249                   NaN             NaN                38  \n1095009                   NaN             NaN                77  \n510386                    NaN             NaN                40  \n4153187                   NaN             NaN                47  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>date_block_num</th>\n      <th>(item_cnt_day, sum)</th>\n      <th>(item_price, median)</th>\n      <th>(revenue, sum)</th>\n      <th>item_category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2895675</th>\n      <td>87747</td>\n      <td>18</td>\n      <td>13236</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>4180000</th>\n      <td>126666</td>\n      <td>52</td>\n      <td>1809</td>\n      <td>23</td>\n      <td>1.0</td>\n      <td>349.0</td>\n      <td>349.0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4195543</th>\n      <td>127137</td>\n      <td>52</td>\n      <td>1866</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>31663</th>\n      <td>959</td>\n      <td>5</td>\n      <td>16988</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4302373</th>\n      <td>130374</td>\n      <td>47</td>\n      <td>7327</td>\n      <td>32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1204528</th>\n      <td>36500</td>\n      <td>12</td>\n      <td>13226</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2156249</th>\n      <td>65340</td>\n      <td>22</td>\n      <td>22013</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>1095009</th>\n      <td>33182</td>\n      <td>10</td>\n      <td>892</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>510386</th>\n      <td>15466</td>\n      <td>3</td>\n      <td>10515</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4153187</th>\n      <td>125854</td>\n      <td>52</td>\n      <td>14969</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(items.shape)\n",
    "print(categories.shape)\n",
    "item_cats = items.merge(categories, how='left', on=['item_category_id'])\n",
    "print(item_cats.shape)\n",
    "print(item_cats.head())\n",
    "item_cats.drop(['item_category_name', 'item_name'], axis=1, inplace=True)\n",
    "print(item_cats.head())\n",
    "print(item_cats['item_id'].nunique())\n",
    "print(item_cats.shape)\n",
    "whole_df = whole_df.merge(item_cats, how='left', on=['item_id'])\n",
    "whole_df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID  shop_id  item_id  date_block_num  total_count  median_price  \\\n",
      "5644900  171057       37    20736              20          0.0           0.0   \n",
      "454855    13783        6    10776              17          0.0           0.0   \n",
      "2320868   70329       24    15298              12          0.0           0.0   \n",
      "2966289   89887       18    15503              19          0.0           0.0   \n",
      "182116     5518        4     2326              23          0.0           0.0   \n",
      "6061810  183691       34     4367               8          0.0           0.0   \n",
      "4359889  132117       47     3418              29          0.0           0.0   \n",
      "2634159   79823       15    11486               1          0.0           0.0   \n",
      "6503934  197088       41    13853              31          0.0           0.0   \n",
      "4406028  133516       48    21670               1          0.0           0.0   \n",
      "\n",
      "         total_revenue  item_category_id  \n",
      "5644900            0.0                72  \n",
      "454855             0.0                55  \n",
      "2320868            0.0                63  \n",
      "2966289            0.0                63  \n",
      "182116             0.0                30  \n",
      "6061810            0.0                19  \n",
      "4359889            0.0                31  \n",
      "2634159            0.0                40  \n",
      "6503934            0.0                37  \n",
      "4406028            0.0                40  \n"
     ]
    }
   ],
   "source": [
    "whole_df.fillna(0, inplace=True)\n",
    "list(whole_df.columns)\n",
    "whole_df.rename(columns={('item_cnt_day', 'sum'):'total_count', ('item_price', 'median'): 'median_price', ('revenue', 'sum'):'total_revenue'}, inplace=True )\n",
    "whole_df['total_count'].clip(0,20)\n",
    "print(whole_df.sample(10))\n",
    "whole_df.to_csv('../Data/Processed/pre_normalised_whole_df.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       total_count  date_block_num  shop_id  item_id  item_category_id  \\\n",
      "15774          0.0               1        5      560                77   \n",
      "15775          0.0               2        5      560                77   \n",
      "15776          0.0               3        5      560                77   \n",
      "15777          0.0               4        5      560                77   \n",
      "15778          0.0               5        5      560                77   \n",
      "15779          0.0               6        5      560                77   \n",
      "15780          0.0               7        5      560                77   \n",
      "15781          0.0               8        5      560                77   \n",
      "15782          1.0               9        5      560                77   \n",
      "15783          0.0              10        5      560                77   \n",
      "15784          0.0              11        5      560                77   \n",
      "15785          0.0              12        5      560                77   \n",
      "15786          0.0              13        5      560                77   \n",
      "15787          0.0              14        5      560                77   \n",
      "15788          0.0              15        5      560                77   \n",
      "15789          0.0              16        5      560                77   \n",
      "15790          0.0              17        5      560                77   \n",
      "15791          0.0              18        5      560                77   \n",
      "15792          0.0              19        5      560                77   \n",
      "15793          0.0              20        5      560                77   \n",
      "15794          0.0              21        5      560                77   \n",
      "15795          0.0              22        5      560                77   \n",
      "15796          0.0              23        5      560                77   \n",
      "15797          0.0              24        5      560                77   \n",
      "15798          0.0              25        5      560                77   \n",
      "15799          0.0              26        5      560                77   \n",
      "15800          0.0              27        5      560                77   \n",
      "15801          0.0              28        5      560                77   \n",
      "15802          0.0              29        5      560                77   \n",
      "15803          0.0              30        5      560                77   \n",
      "15804          0.0              31        5      560                77   \n",
      "15805          0.0              32        5      560                77   \n",
      "15806          0.0              33        5      560                77   \n",
      "16269          0.0               1        5      562                77   \n",
      "\n",
      "       median_price  \n",
      "15774           0.0  \n",
      "15775           0.0  \n",
      "15776           0.0  \n",
      "15777           0.0  \n",
      "15778           0.0  \n",
      "15779           0.0  \n",
      "15780           0.0  \n",
      "15781           0.0  \n",
      "15782         199.0  \n",
      "15783           0.0  \n",
      "15784           0.0  \n",
      "15785           0.0  \n",
      "15786           0.0  \n",
      "15787           0.0  \n",
      "15788           0.0  \n",
      "15789           0.0  \n",
      "15790           0.0  \n",
      "15791           0.0  \n",
      "15792           0.0  \n",
      "15793           0.0  \n",
      "15794           0.0  \n",
      "15795           0.0  \n",
      "15796           0.0  \n",
      "15797           0.0  \n",
      "15798           0.0  \n",
      "15799           0.0  \n",
      "15800           0.0  \n",
      "15801           0.0  \n",
      "15802           0.0  \n",
      "15803           0.0  \n",
      "15804           0.0  \n",
      "15805           0.0  \n",
      "15806           0.0  \n",
      "16269           0.0  \n",
      "(242550, 6)\n",
      "[[[0.00e+00 1.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [1.00e+00 3.00e+00 5.00e+00 8.39e+02 7.30e+01 3.30e+03]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]]]\n"
     ]
    }
   ],
   "source": [
    "whole_df.sort_values(by=['ID', 'date_block_num'])\n",
    "whole_df = whole_df[whole_df['item_id'] <= 1000]\n",
    "whole_df.drop(['ID', 'total_revenue'], axis=1, inplace=True)\n",
    "whole_df = whole_df[['total_count', 'date_block_num', 'shop_id', 'item_id', 'item_category_id', 'median_price']]\n",
    "print(whole_df.head(34))\n",
    "whole_df_arr = whole_df.values\n",
    "print(whole_df_arr.shape)\n",
    "whole_df_arr = whole_df_arr.reshape(7350, 33, 6)\n",
    "print(whole_df_arr)#change back to 214200\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7350, 26, 6)\n",
      "(7350, 7, 6)\n",
      "(7350, 6, 6)\n",
      "[[[0.00e+00 1.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [1.00e+00 3.00e+00 5.00e+00 8.39e+02 7.30e+01 3.30e+03]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]]]\n"
     ]
    }
   ],
   "source": [
    "#prepare training and validation sets\n",
    "train_arr = whole_df_arr[:, :26]\n",
    "val_arr = whole_df_arr[:, 26:]\n",
    "print(train_arr.shape)\n",
    "print(val_arr.shape)\n",
    "train_arr_first_test = train_arr[:, 19:25]\n",
    "print(train_arr_first_test.shape)\n",
    "print(train_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.09934477 -1.66666667 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4        -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4        -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [ 0.66849284 -1.4        -1.51708349  1.04790289  0.95110686\n",
      "    7.56414848]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]]]\n"
     ]
    }
   ],
   "source": [
    "#normalise data\n",
    "\n",
    "train_mean = train_arr.mean(axis=(0, 1))\n",
    "train_std = train_arr.std(axis=(0, 1))\n",
    "train_arr = (train_arr - train_mean)/train_std\n",
    "print(train_arr)\n",
    "val_arr = (val_arr - train_mean)/train_std\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#train_arr = list(train_arr)\n",
    "\n",
    "#train_arr = train_arr[0:3]\n",
    "train_list = list(train_arr)\n",
    "val_list = list(val_arr)\n",
    "first_test_list = list(train_arr_first_test)\n",
    "#def split_sequences(sequences, n_steps):\n",
    "#    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09934476591470832\n",
      "(147000, 6, 6)\n",
      "(7350,)\n"
     ]
    }
   ],
   "source": [
    "#get sliding windows for each ID\n",
    "train_x, train_y = [],[]\n",
    "val_x, val_y = [],[]\n",
    "def get_windows(sequence, n_steps, x, y):\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "    # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix][0]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "for example in train_list:\n",
    "    get_windows(example, 6, train_x, train_y)\n",
    "for example in val_list:\n",
    "    get_windows(example, 6, val_x, val_y)\n",
    "print(val_y[0])\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "print(train_x.shape)\n",
    "print(val_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.19542789  1.19542789  1.19542789  1.19542789  1.19542789  1.19542789]\n",
      " [ 1.19542789  1.19542789  1.19542789  1.19542789  1.19542789  1.19542789]\n",
      " [ 1.19542789  1.19542789  1.19542789  1.19542789  1.19542789  1.19542789]\n",
      " ...\n",
      " [-1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824 ]\n",
      " [-1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824 ]\n",
      " [-1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824  -1.2477824 ]]\n",
      "(147000, 6, 13)\n"
     ]
    }
   ],
   "source": [
    "shop_id_x = train_x[:, :, 2]\n",
    "shop_id_val_x = val_x[:, :, 2]\n",
    "train_x = np.delete(train_x, 2, axis=2)\n",
    "print(shop_id_x)\n",
    "input_dim = len(set(tuple(shop_id_x.flatten())))\n",
    "shop_id_input = tf.keras.Input(shape=(6,1))\n",
    "numerical_input = tf.keras.Input(shape=(6, 5))\n",
    "shop_id_embed = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=8)(shop_id_input)\n",
    "shop_id_flatten = tf.reshape(shop_id_embed, shape=[147000, 6, 8])\n",
    "\n",
    "combine_input = tf.keras.layers.Concatenate()([shop_id_flatten, numerical_input])\n",
    "model_shop_id = tf.keras.Model([shop_id_input, numerical_input], combine_input)\n",
    "print(combine_input.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:155 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(40, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(40, 6, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-63-878509ea60f3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mtotal_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mshop_id_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumerical_input\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdense_1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"mse\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"adam\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mshop_id_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_x\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m40\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[0;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1098\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1099\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    821\u001B[0m       \u001B[1;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    822\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 823\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    824\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    825\u001B[0m       \u001B[1;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[1;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[0;32m    694\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_graph_deleter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFunctionDeleter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lifted_initializer_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    695\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m--> 696\u001B[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    697\u001B[0m             *args, **kwds))\n\u001B[0;32m    698\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2853\u001B[0m       \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2854\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2855\u001B[1;33m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2856\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2857\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3213\u001B[1;33m       \u001B[0mgraph_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3214\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3215\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3063\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3064\u001B[0m     graph_function = ConcreteFunction(\n\u001B[1;32m-> 3065\u001B[1;33m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[0;32m   3066\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3067\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    985\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 986\u001B[1;33m       \u001B[0mfunc_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    987\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    988\u001B[0m       \u001B[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    598\u001B[0m         \u001B[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    599\u001B[0m         \u001B[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 600\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    601\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mref\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    602\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    971\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    972\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 973\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    974\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    975\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    e:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:155 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(40, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(40, 6, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12))(combine_input)\n",
    "dense_1 = tf.keras.layers.Dense(1)(lstm_1)\n",
    "total_model = tf.keras.Model([shop_id_input, numerical_input], dense_1)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(x=[shop_id_x, train_x], y=train_y, validation_data=(val_x, val_y), epochs=10, batch_size=40, verbose=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    " #      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12, input_shape=(6,6))),\n",
    " #   tf.keras.layers.Dense(1)\n",
    "#])\n",
    "\n",
    "#model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "#history = model.fit(x=train_x, y=train_y, validation_data=(val_x, val_y), epochs=100, batch_size=40, verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_predict_function_2880]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-56e1ee2532e4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m#print(train_arr[:,-7:-1])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#create prediction window excluding last value to compare\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_arr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_arr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mdenormalised_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mtrain_std\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtrain_mean\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001B[0;32m    129\u001B[0m           method.__name__))\n\u001B[1;32m--> 130\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    131\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m   return tf_decorator.make_decorator(\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1597\u001B[0m           \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1598\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_predict_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1599\u001B[1;33m             \u001B[0mtmp_batch_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1600\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1601\u001B[0m               \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    839\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 840\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    841\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m       \u001B[0mcanon_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcanon_kwds\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2829\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2831\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1841\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m     \"\"\"\n\u001B[1;32m-> 1843\u001B[1;33m     return self._call_flat(\n\u001B[0m\u001B[0;32m   1844\u001B[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[0;32m   1845\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1921\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1922\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1923\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1924\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    546\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnknownError\u001B[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_predict_function_2880]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "#print(val_arr)\n",
    "#print(train_arr[:,-7:-1])\n",
    "#create prediction window excluding last value to compare\n",
    "predictions = model.predict(val_arr[:,:-1])\n",
    "predictions = model.predict(train_arr[:,-7:-1])\n",
    "denormalised_predictions = predictions*train_std[0] + train_mean[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(denormalised_predictions.astype(int))\n",
    "print(train_mean)\n",
    "print(train_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}