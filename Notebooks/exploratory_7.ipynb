{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_name  item_id  \\\n",
      "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
      "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
      "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
      "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
      "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
      "\n",
      "   item_category_id  \n",
      "0                40  \n",
      "1                76  \n",
      "2                40  \n",
      "3                40  \n",
      "4                40  \n",
      "(22170, 3)\n",
      "(22170, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "items = pd.read_csv(r\"..\\Data\\Raw\\items.csv\", delimiter=\",\")\n",
    "print(items.head())\n",
    "print(items.shape)\n",
    "items = items.drop_duplicates(subset=['item_name'], keep=False)\n",
    "print(items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  shop_id  item_id\n",
      "0   0        5     5037\n",
      "1   1        5     5320\n",
      "2   2        5     5233\n",
      "3   3        5     5232\n",
      "4   4        5     5268\n",
      "42\n",
      "214200\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(r\"..\\Data\\Raw\\test.csv\", delimiter=\",\")\n",
    "print(test.head())\n",
    "print(test['shop_id'].nunique())\n",
    "print(test['ID'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
      "0  02.01.2013               0       59    22154      999.00           1.0\n",
      "1  03.01.2013               0       25     2552      899.00           1.0\n",
      "2  05.01.2013               0       25     2552      899.00          -1.0\n",
      "3  06.01.2013               0       25     2554     1709.05           1.0\n",
      "4  15.01.2013               0       25     2555     1099.00           1.0\n",
      "(2935849, 6)\n",
      "(2935793, 6)\n",
      "(2935789, 6)\n",
      "                               item_cnt_day item_price revenue\n",
      "                                        sum     median     sum\n",
      "date_block_num shop_id item_id                                \n",
      "0              0       32               6.0      221.0  1326.0\n",
      "                       33               3.0      347.0  1041.0\n",
      "                       35               1.0      247.0   247.0\n",
      "                       43               1.0      221.0   221.0\n",
      "                       51               2.0      128.5   257.0\n",
      "                       61               1.0      195.0   195.0\n",
      "                       75               1.0       76.0    76.0\n",
      "                       88               1.0       76.0    76.0\n",
      "                       95               1.0      193.0   193.0\n",
      "                       96               1.0       70.0    70.0\n",
      "                       98              25.0      268.0  6700.0\n",
      "                       111              1.0       89.0    89.0\n",
      "                       149              3.0       99.0   297.0\n",
      "                       151              1.0       75.0    75.0\n",
      "                       153              1.0      258.0   258.0\n",
      "                       198              1.0      112.0   112.0\n",
      "                       210              2.0      118.0   236.0\n",
      "                       282              1.0      109.0   109.0\n",
      "                       306              1.0       59.0    59.0\n",
      "                       351              1.0       89.0    89.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               item_cnt_day item_price  revenue\n                                        sum     median      sum\ndate_block_num shop_id item_id                                 \n11             42      15472            1.0      749.0    749.0\n13             24      2896             1.0      599.0    599.0\n5              37      11620            1.0      199.0    199.0\n8              56      9508             1.0      298.0    298.0\n22             24      3332             5.0      599.0   2995.0\n9              45      11463            1.0      349.0    349.0\n12             41      1415             1.0     1999.0   1999.0\n               31      10674            2.0      550.0   1100.0\n2              43      4033             1.0      419.0    419.0\n11             26      1512            10.0     2599.0  25990.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>item_cnt_day</th>\n      <th>item_price</th>\n      <th>revenue</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>sum</th>\n      <th>median</th>\n      <th>sum</th>\n    </tr>\n    <tr>\n      <th>date_block_num</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <th>42</th>\n      <th>15472</th>\n      <td>1.0</td>\n      <td>749.0</td>\n      <td>749.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <th>24</th>\n      <th>2896</th>\n      <td>1.0</td>\n      <td>599.0</td>\n      <td>599.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <th>37</th>\n      <th>11620</th>\n      <td>1.0</td>\n      <td>199.0</td>\n      <td>199.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <th>56</th>\n      <th>9508</th>\n      <td>1.0</td>\n      <td>298.0</td>\n      <td>298.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <th>24</th>\n      <th>3332</th>\n      <td>5.0</td>\n      <td>599.0</td>\n      <td>2995.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <th>45</th>\n      <th>11463</th>\n      <td>1.0</td>\n      <td>349.0</td>\n      <td>349.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">12</th>\n      <th>41</th>\n      <th>1415</th>\n      <td>1.0</td>\n      <td>1999.0</td>\n      <td>1999.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <th>10674</th>\n      <td>2.0</td>\n      <td>550.0</td>\n      <td>1100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>43</th>\n      <th>4033</th>\n      <td>1.0</td>\n      <td>419.0</td>\n      <td>419.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <th>26</th>\n      <th>1512</th>\n      <td>10.0</td>\n      <td>2599.0</td>\n      <td>25990.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(r\"..\\Data\\Raw\\sales_train.csv\", delimiter=\",\")\n",
    "print(sales.head())\n",
    "print(sales.shape)\n",
    "sales = sales.drop_duplicates(subset=['date', 'shop_id', 'item_id'], keep=False)\n",
    "print(sales.shape)\n",
    "sales = sales[sales.item_cnt_day<1000]\n",
    "sales = sales[sales.item_price<60000]\n",
    "sales = sales[sales.item_price>0]\n",
    "print(sales.shape)\n",
    "sales['revenue'] = sales['item_cnt_day'] * sales['item_price']\n",
    "sales_monthly = sales.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg({'item_cnt_day': ['sum'], 'item_price':['median'], 'revenue':['sum']})\n",
    "print(sales_monthly.head(20))\n",
    "sales_monthly.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_block_num\n",
      "0               1\n",
      "1               2\n",
      "2               3\n",
      "3               4\n",
      "4               5\n",
      "(7068600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\latest pycharm\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#join to test set to get only necessary IDs\n",
    "month_range = range(1, 34)\n",
    "month_df = pd.DataFrame(month_range)\n",
    "\n",
    "month_df.rename(columns={0 :'date_block_num'}, inplace=True )\n",
    "print(month_df.head())\n",
    "month_df['temp'] = 1\n",
    "test['temp'] = 1\n",
    "test_monthly = test.merge(month_df, on=['temp'])\n",
    "test_monthly.drop(['temp'], axis=1, inplace=True)\n",
    "whole_df = test_monthly.merge(sales_monthly, how='left', on=['date_block_num', 'item_id', 'shop_id'])\n",
    "whole_df.sample(10)\n",
    "print(whole_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item_category_name  item_category_id\n",
      "0  PC - Гарнитуры/Наушники                 0\n",
      "1         Аксессуары - PS2                 1\n",
      "2         Аксессуары - PS3                 2\n",
      "3         Аксессуары - PS4                 3\n",
      "4         Аксессуары - PSP                 4\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_csv(r\"..\\Data\\Raw\\item_categories.csv\", delimiter=\",\")\n",
    "print(categories.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22170, 3)\n",
      "(84, 2)\n",
      "(22170, 4)\n",
      "                                           item_name  item_id  \\\n",
      "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
      "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
      "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
      "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
      "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
      "\n",
      "   item_category_id                    item_category_name  \n",
      "0                40                            Кино - DVD  \n",
      "1                76  Программы - Для дома и офиса (Цифра)  \n",
      "2                40                            Кино - DVD  \n",
      "3                40                            Кино - DVD  \n",
      "4                40                            Кино - DVD  \n",
      "   item_id  item_category_id\n",
      "0        0                40\n",
      "1        1                76\n",
      "2        2                40\n",
      "3        3                40\n",
      "4        4                40\n",
      "22170\n",
      "(22170, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "             ID  shop_id  item_id  date_block_num  (item_cnt_day, sum)  \\\n1951162   59126       25     3000               5                  NaN   \n6501062  197001       41    14979              30                  NaN   \n5508922  166937       36    17321               2                  NaN   \n2381549   72168       21    12020               6                  NaN   \n4924501  149227       59    21460              11                  NaN   \n3520749  106689       42     2264              13                  NaN   \n3009484   91196       18    16374              17                  NaN   \n549730    16658        3    18579              17                  NaN   \n4383821  132843       48     6743               3                  NaN   \n5674204  171945       37     8808              20                  NaN   \n\n         (item_price, median)  (revenue, sum)  item_category_id  \n1951162                   NaN             NaN                75  \n6501062                   NaN             NaN                61  \n5508922                   NaN             NaN                37  \n2381549                   NaN             NaN                40  \n4924501                   NaN             NaN                40  \n3520749                   NaN             NaN                31  \n3009484                   NaN             NaN                31  \n549730                    NaN             NaN                37  \n4383821                   NaN             NaN                29  \n5674204                   NaN             NaN                40  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>date_block_num</th>\n      <th>(item_cnt_day, sum)</th>\n      <th>(item_price, median)</th>\n      <th>(revenue, sum)</th>\n      <th>item_category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1951162</th>\n      <td>59126</td>\n      <td>25</td>\n      <td>3000</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>6501062</th>\n      <td>197001</td>\n      <td>41</td>\n      <td>14979</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>5508922</th>\n      <td>166937</td>\n      <td>36</td>\n      <td>17321</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2381549</th>\n      <td>72168</td>\n      <td>21</td>\n      <td>12020</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4924501</th>\n      <td>149227</td>\n      <td>59</td>\n      <td>21460</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3520749</th>\n      <td>106689</td>\n      <td>42</td>\n      <td>2264</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3009484</th>\n      <td>91196</td>\n      <td>18</td>\n      <td>16374</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>549730</th>\n      <td>16658</td>\n      <td>3</td>\n      <td>18579</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>4383821</th>\n      <td>132843</td>\n      <td>48</td>\n      <td>6743</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>5674204</th>\n      <td>171945</td>\n      <td>37</td>\n      <td>8808</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(items.shape)\n",
    "print(categories.shape)\n",
    "item_cats = items.merge(categories, how='left', on=['item_category_id'])\n",
    "print(item_cats.shape)\n",
    "print(item_cats.head())\n",
    "item_cats.drop(['item_category_name', 'item_name'], axis=1, inplace=True)\n",
    "print(item_cats.head())\n",
    "print(item_cats['item_id'].nunique())\n",
    "print(item_cats.shape)\n",
    "whole_df = whole_df.merge(item_cats, how='left', on=['item_id'])\n",
    "whole_df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID  shop_id  item_id  date_block_num  total_count  median_price  \\\n",
      "6814432  206497       39     4002              32          0.0           0.0   \n",
      "1404270   42553       28    13330              22          0.0           0.0   \n",
      "3503609  106169       42     7342              33          0.0           0.0   \n",
      "4821213  146097       58    12752              13          0.0           0.0   \n",
      "1030446   31225       10     3920              22          0.0           0.0   \n",
      "953965    28908        7    15586               2          0.0           0.0   \n",
      "1947128   59003       25    16459              30          0.0           0.0   \n",
      "1570069   47577       31    19597              29          1.0         169.0   \n",
      "3102447   94013       14    18595              19          0.0           0.0   \n",
      "6374788  193175       46    14204              14          0.0           0.0   \n",
      "\n",
      "         total_revenue  item_category_id  \n",
      "6814432            0.0                55  \n",
      "1404270            0.0                47  \n",
      "3503609            0.0                55  \n",
      "4821213            0.0                37  \n",
      "1030446            0.0                56  \n",
      "953965             0.0                40  \n",
      "1947128            0.0                55  \n",
      "1570069          169.0                40  \n",
      "3102447            0.0                41  \n",
      "6374788            0.0                31  \n"
     ]
    }
   ],
   "source": [
    "whole_df.fillna(0, inplace=True)\n",
    "list(whole_df.columns)\n",
    "whole_df.rename(columns={('item_cnt_day', 'sum'):'total_count', ('item_price', 'median'): 'median_price', ('revenue', 'sum'):'total_revenue'}, inplace=True )\n",
    "whole_df['total_count'].clip(0,20)\n",
    "print(whole_df.sample(10))\n",
    "whole_df.to_csv('../Data/Processed/pre_normalised_whole_df.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       total_count  date_block_num  shop_id  item_id  item_category_id  \\\n",
      "15774          0.0               1        5      560                77   \n",
      "15775          0.0               2        5      560                77   \n",
      "15776          0.0               3        5      560                77   \n",
      "15777          0.0               4        5      560                77   \n",
      "15778          0.0               5        5      560                77   \n",
      "15779          0.0               6        5      560                77   \n",
      "15780          0.0               7        5      560                77   \n",
      "15781          0.0               8        5      560                77   \n",
      "15782          1.0               9        5      560                77   \n",
      "15783          0.0              10        5      560                77   \n",
      "15784          0.0              11        5      560                77   \n",
      "15785          0.0              12        5      560                77   \n",
      "15786          0.0              13        5      560                77   \n",
      "15787          0.0              14        5      560                77   \n",
      "15788          0.0              15        5      560                77   \n",
      "15789          0.0              16        5      560                77   \n",
      "15790          0.0              17        5      560                77   \n",
      "15791          0.0              18        5      560                77   \n",
      "15792          0.0              19        5      560                77   \n",
      "15793          0.0              20        5      560                77   \n",
      "15794          0.0              21        5      560                77   \n",
      "15795          0.0              22        5      560                77   \n",
      "15796          0.0              23        5      560                77   \n",
      "15797          0.0              24        5      560                77   \n",
      "15798          0.0              25        5      560                77   \n",
      "15799          0.0              26        5      560                77   \n",
      "15800          0.0              27        5      560                77   \n",
      "15801          0.0              28        5      560                77   \n",
      "15802          0.0              29        5      560                77   \n",
      "15803          0.0              30        5      560                77   \n",
      "15804          0.0              31        5      560                77   \n",
      "15805          0.0              32        5      560                77   \n",
      "15806          0.0              33        5      560                77   \n",
      "16269          0.0               1        5      562                77   \n",
      "\n",
      "       median_price  \n",
      "15774           0.0  \n",
      "15775           0.0  \n",
      "15776           0.0  \n",
      "15777           0.0  \n",
      "15778           0.0  \n",
      "15779           0.0  \n",
      "15780           0.0  \n",
      "15781           0.0  \n",
      "15782         199.0  \n",
      "15783           0.0  \n",
      "15784           0.0  \n",
      "15785           0.0  \n",
      "15786           0.0  \n",
      "15787           0.0  \n",
      "15788           0.0  \n",
      "15789           0.0  \n",
      "15790           0.0  \n",
      "15791           0.0  \n",
      "15792           0.0  \n",
      "15793           0.0  \n",
      "15794           0.0  \n",
      "15795           0.0  \n",
      "15796           0.0  \n",
      "15797           0.0  \n",
      "15798           0.0  \n",
      "15799           0.0  \n",
      "15800           0.0  \n",
      "15801           0.0  \n",
      "15802           0.0  \n",
      "15803           0.0  \n",
      "15804           0.0  \n",
      "15805           0.0  \n",
      "15806           0.0  \n",
      "16269           0.0  \n",
      "(242550, 6)\n",
      "[[[0.00e+00 1.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [1.00e+00 3.00e+00 5.00e+00 8.39e+02 7.30e+01 3.30e+03]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 3.10e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.20e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.30e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]]]\n"
     ]
    }
   ],
   "source": [
    "whole_df.sort_values(by=['ID', 'date_block_num'])\n",
    "whole_df = whole_df[whole_df['item_id'] <= 1000]\n",
    "whole_df.drop(['ID', 'total_revenue'], axis=1, inplace=True)\n",
    "whole_df = whole_df[['total_count', 'date_block_num', 'shop_id', 'item_id', 'item_category_id', 'median_price']]\n",
    "print(whole_df.head(34))\n",
    "whole_df_arr = whole_df.values\n",
    "print(whole_df_arr.shape)\n",
    "whole_df_arr = whole_df_arr.reshape(7350, 33, 6)\n",
    "print(whole_df_arr)#change back to 214200\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7350, 26, 6)\n",
      "(7350, 7, 6)\n",
      "(7350, 6, 6)\n",
      "[[[0.00e+00 1.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 5.60e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 5.62e+02 7.70e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [1.00e+00 3.00e+00 5.00e+00 8.39e+02 7.30e+01 3.30e+03]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 5.00e+00 8.39e+02 7.30e+01 0.00e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 1.73e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 1.54e+02 4.50e+01 0.00e+00]]\n",
      "\n",
      " [[0.00e+00 1.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 3.00e+00 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  ...\n",
      "  [0.00e+00 2.40e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.50e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]\n",
      "  [0.00e+00 2.60e+01 4.50e+01 9.69e+02 3.70e+01 0.00e+00]]]\n"
     ]
    }
   ],
   "source": [
    "#prepare training and validation sets\n",
    "train_arr = whole_df_arr[:, :26]\n",
    "val_arr = whole_df_arr[:, 26:]\n",
    "print(train_arr.shape)\n",
    "print(val_arr.shape)\n",
    "train_arr_first_test = train_arr[:, 19:25]\n",
    "print(train_arr_first_test.shape)\n",
    "print(train_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.09934477 -1.66666667 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4        -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  0.10151063  1.19542789\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4        -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  0.1082948   1.19542789\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [ 0.66849284 -1.4        -1.51708349  1.04790289  0.95110686\n",
      "    7.56414848]\n",
      "  ...\n",
      "  [-0.09934477  1.4        -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667 -1.51708349  1.04790289  0.95110686\n",
      "   -0.1184017 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537 -1.21122704 -0.75914034\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537 -1.27567669 -0.75914034\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.09934477 -1.66666667  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.53333333  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477 -1.4         0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  ...\n",
      "  [-0.09934477  1.4         0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.53333333  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]\n",
      "  [-0.09934477  1.66666667  0.76057537  1.4888742  -1.2477824\n",
      "   -0.1184017 ]]]\n"
     ]
    }
   ],
   "source": [
    "#normalise data\n",
    "\n",
    "train_mean = train_arr.mean(axis=(0, 1))\n",
    "train_std = train_arr.std(axis=(0, 1))\n",
    "train_arr = (train_arr - train_mean)/train_std\n",
    "print(train_arr)\n",
    "val_arr = (val_arr - train_mean)/train_std\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#train_arr = list(train_arr)\n",
    "\n",
    "#train_arr = train_arr[0:3]\n",
    "train_list = list(train_arr)\n",
    "val_list = list(val_arr)\n",
    "first_test_list = list(train_arr_first_test)\n",
    "#def split_sequences(sequences, n_steps):\n",
    "#    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09934476591470832\n",
      "(147000, 6, 6)\n",
      "(7350,)\n"
     ]
    }
   ],
   "source": [
    "#get sliding windows for each ID\n",
    "train_x, train_y = [],[]\n",
    "val_x, val_y = [],[]\n",
    "def get_windows(sequence, n_steps, x, y):\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "    # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix][0]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "for example in train_list:\n",
    "    get_windows(example, 6, train_x, train_y)\n",
    "for example in val_list:\n",
    "    get_windows(example, 6, val_x, val_y)\n",
    "print(val_y[0])\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "print(train_x.shape)\n",
    "print(val_y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147000, 6, 5)\n",
      "(147000, 6)\n",
      "(None, 6, 13)\n",
      "Model: \"functional_60\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_56 (Embedding)        (None, 6, 8)         4000000     input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           [(None, 6, 5)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 6, 13)        0           embedding_56[0][0]               \n",
      "                                                                 input_54[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,000,000\n",
      "Trainable params: 4,000,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shop_id_x = train_x[:, :, 2]\n",
    "\n",
    "shop_id_val_x = val_x[:, :, 2]\n",
    "train_x = np.delete(train_x, 2, axis=2)\n",
    "val_x = np.delete(val_x, 2, axis=2)\n",
    "print(train_x.shape)\n",
    "\n",
    "\n",
    "shop_id_x = shop_id_x*train_std[2] + train_mean[2]\n",
    "shop_id_val_x = shop_id_val_x*train_std[2] + train_mean[2]\n",
    "print(shop_id_x.shape)\n",
    "\n",
    "shop_id_input = tf.keras.Input(shape=(6))\n",
    "numerical_input = tf.keras.Input(shape=(6, 5))\n",
    "shop_id_embed = tf.keras.layers.Embedding(input_dim=500000, input_length=(6,1), output_dim=8)(shop_id_input)\n",
    "#shop_id_flatten = tf.reshape(shop_id_embed, shape=(6, 8))\n",
    "#shop_id_flatten = tf.keras.layers.Flatten()(shop_id_embed)\n",
    "combine_input = tf.keras.layers.Concatenate()([shop_id_embed, numerical_input])\n",
    "model_shop_id = tf.keras.Model([shop_id_input, numerical_input], combine_input)\n",
    "print(combine_input.shape)\n",
    "from keras.utils import plot_model\n",
    "plot_model(model_shop_id, to_file='model.png')\n",
    "model_shop_id.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.]\n",
      " [ 5.  5.  5.  5.  5.  5.]\n",
      " ...\n",
      " [45. 45. 45. 45. 45. 45.]\n",
      " [45. 45. 45. 45. 45. 45.]\n",
      " [45. 45. 45. 45. 45. 45.]]\n",
      "WARNING:tensorflow:Layer concatenate_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]\n",
      "  [ 0.01990293 -0.04864485 -0.0389986  ...  0.10151063  1.1954279\n",
      "   -0.1184017 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "    1.1596953 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "    1.1596953 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "    1.1596953 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]]\n",
      "\n",
      " [[-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]\n",
      "  [-0.01807706  0.03218189  0.03519127 ...  1.4888742  -1.2477823\n",
      "   -0.1184017 ]]], shape=(147000, 6, 13), dtype=float32)\n",
      "(147000, 6, 13)\n"
     ]
    }
   ],
   "source": [
    "integer_arr = tf.constant([[1],[2],[3]])\n",
    "embedding_layer = tf.keras.layers.Embedding(100, 3)\n",
    "print(shop_id_x)\n",
    "shop_id_embed = tf.keras.layers.Embedding(input_dim=1000, input_length=(6,1), output_dim=8)(shop_id_x)\n",
    "combine_input = tf.keras.layers.Concatenate()([shop_id_embed, train_x])\n",
    "print(combine_input)\n",
    "print(combine_input.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node gradient_tape/functional_56/embedding_54/embedding_lookup/Reshape/_38}}]] [Op:__inference_train_function_43869]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-93-850d9b13e5f5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mtotal_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"mse\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"adam\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtotal_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mshop_id_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_x\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mshop_id_val_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_x\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[0;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1098\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1099\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    839\u001B[0m         \u001B[1;31m# stateless function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 840\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    841\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m       \u001B[0mcanon_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcanon_kwds\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2829\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2831\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1841\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m     \"\"\"\n\u001B[1;32m-> 1843\u001B[1;33m     return self._call_flat(\n\u001B[0m\u001B[0;32m   1844\u001B[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[0;32m   1845\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1921\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1922\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1923\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1924\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    546\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\latest pycharm\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mCancelledError\u001B[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node gradient_tape/functional_56/embedding_54/embedding_lookup/Reshape/_38}}]] [Op:__inference_train_function_43869]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12))(combine_input)\n",
    "dense_1 = tf.keras.layers.Dense(1)(lstm_1)\n",
    "total_model = tf.keras.Model([shop_id_input, numerical_input], dense_1)\n",
    "\n",
    "\n",
    "total_model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = total_model.fit(x=[shop_id_x, train_x], y=train_y, validation_data=([shop_id_val_x, val_x], val_y), epochs=10, verbose=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    " #      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12, input_shape=(6,6))),\n",
    " #   tf.keras.layers.Dense(1)\n",
    "#])\n",
    "\n",
    "#model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "#history = model.fit(x=train_x, y=train_y, validation_data=(val_x, val_y), epochs=100, batch_size=40, verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(val_arr)\n",
    "#print(train_arr[:,-7:-1])\n",
    "#create prediction window excluding last value to compare\n",
    "predictions = model.predict(val_arr[:,:-1])\n",
    "predictions = model.predict(train_arr[:,-7:-1])\n",
    "denormalised_predictions = predictions*train_std[0] + train_mean[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(denormalised_predictions.astype(int))\n",
    "print(train_mean)\n",
    "print(train_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}